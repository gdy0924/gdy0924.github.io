<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Paper on XY&#39;s Blog</title>
    <link>https://gdy0924.github.io/categories/paper/</link>
    <description>Recent content in Paper on XY&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://gdy0924.github.io/categories/paper/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ShuffleNet</title>
      <link>https://gdy0924.github.io/posts/shufflenet/</link>
      <pubDate>Wed, 06 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/shufflenet/</guid>
      <description>ShuffleNet 原文链接：ShuffleNet
Abstract  引入了一种计算效率非常高的CNN架构，名为ShuffleNet，它是专门为计算能力非常有限的移动设备而设计的。新的架构采用了两种新的操作，pointwise group convolution和channel shuffle，在保持精度的同时大大降低了计算成本。
Introduction  构建更深更大的卷积神经网络(CNNs)是解决主要视觉识别任务的主要趋势。最精确的CNN通常有数百层和数千个通道，因此需要的计算量非常大。但在非常有限的计算预算下，也需要追求最佳的准确性，如无人机，如无人机、机器人和智能手机等通用移动平台。但现有的许多工作都专注于剪枝、压缩或低位表示一个“基本的”网络架构。在本文，我们的目标是探索一个高效的基本结构。
性能好的网络如Xception和ResNeXt，在规模小的网络中效率较低，因为密集的1×1卷积很昂贵。我们提出使用pointwise group convolution来降低1×1卷积的计算复杂度，为了克服group convolution带来的副作用，提出一种新的操作：channel shuffle，可以使信息在通道中流通。基于上述两种技术，构建一个高效的结构：ShuffleNet。相比于其他架构，对于给定的计算复杂度，可以实现更多的特征图通道，以编码更多信息，这对于很小的网络性能是很重要的。
Related Work Efficient Model Designs  深度神经网络在计算机视觉任务中取得的成功，模型设计发挥了重要的作用。例如，与简单的叠加卷积层相比，GoogLeNet以更低的复杂度增加了网络的深度。SqueezeNet在保持精度的同时显著减少了参数和计算。ResNet利用高效的bottleneck结构来实现令人印象深刻的性能。SENet引入了一个架构单元，可以以轻微的计算成本提高性能。与此同时，最近的一项工作采用了强化学习和模型搜索来探索有效的模型设计，所提出的移动NASNet模型达到了与我们对应的ShuffleNet模型相当的性能，但是NASNet并没有报告在极小的模型上的结果，也没有评估在移动设备上的实际测试时间。
Group Convolution  Group Convolution的概念首次在AlexNet中引入，用于将模型分布在两个GPU上，在ResNeXt中很好地证明了其有效性。在Xception中提出的深度可分离卷积depthwise separable convolution。最近，MobileNet利用深度可分离的卷积，并在轻量级模型中获得了最先进的结果。我们的工作以一种新的形式推广了group convolution和depthwise separable convolution。
Channel Shuffle Operation  channel shuffle操作的想法在之前的高效模型设计中几乎没有被提到过，即使CNN库cuda-convnet支持随机稀疏卷积(random sparse convolution)层，相当于group convolution之后进行channel shuffle。这种random shuffle操作很少被使用。最近，另一个工作也采用了这个想法来进行两阶段卷积，但其并没有专门研究channel shuffle本身的有效性及其在小模型设计中的应用。
Model Acceleration  在加速推理的同时，保证预训练模型的准确性。
Approach Channel Shuffle for Group Convolutions  Xception和ResNeXt，在构建块中引入高效的深度可分离卷积或组卷积，以在表示能力和计算成本之间取得良好的权衡。然而，我们注意到，这两种设计都没有完全考虑到1×1卷积（也称为Pointwise Convolution），需要相当大的复杂性。在小型网络中，昂贵的Pointwise Convolution导致通道数量有限，可能会严重损害精度。
为了解决这个问题，一个简单的解决方法是使用通道稀疏连接，例如组卷积也同样应用在1×1卷积上。通过确保每个卷积只在相应的输入通道组上操作，组卷积大大降低了计算成本。然而，如果多个组卷积堆叠在一起，就有一个副作用：某个通道的输出只与输入通道的一小部分有关。如上图中的（a）显示了两个堆叠的组卷积。很明显，来自某一组的输出只与组内的输入有关，这阻止了通道组之间的信息交流。
如果我们允许组卷积获得来自不同组的输入数据，如上图中的（b）所示，那么输入通道和输出通道将完全相关。具体来说，对于上一组层生成的特征图，我们可以首先将每个组中的通道划分为几个子组，然后向下一层中的每个组提供不同的子组。这可以通过channel shuffle操作实现，如上图中的（c）：假设一个卷积层，有g个组，输出有g×n个通道，即每组的输出通道为n；我们首先将输出通道维度重塑为(g，n)，然后将其转平，作为下一层的输入，如下图所示： ShuffleNet Unit  利用channel shuffle操作，我们提出了ShuffleNet网络。从下图中的（a）模块出发，它是一个残差模块。其中3×3的卷积使用深度可分离卷积实现，将第一个1×1卷积替换成点组卷积紧跟着一个channel shuffle，形成一个ShuffleNet Unit，如下图的（b）所示，第二个点组卷积是为了恢复通道数目，以匹配shortcut连接。对于下采样模块，我们进行了两个修改，如下图（c）所示：（1）在shortcut通路上添加了一个平均池化层；（2）用通道连接替换元素相加，可以扩大通道，无需额外的计算成本。 由于点组卷积与channel shuffle，ShuffleNet Unit相同的设置下具有更小的复杂性，与ResNet和ResNeXt相比，例如：对于输入通道c，输出通道m，分组g的模块来说，ResNet需要$ 2cm+9m^{2}$，ResNeXt需要$ 2cm+\frac{9m^{2}}{g}$，而ShuffleNet 需要$\frac{2cm}{g}+9m$。即在相同的计算量下，ShuffleNet可以拥有更多的通道数。</description>
    </item>
    
    <item>
      <title>ResNet</title>
      <link>https://gdy0924.github.io/posts/resnet/</link>
      <pubDate>Tue, 05 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/resnet/</guid>
      <description>ResNet 原文连接：ResNet
Abstract  更深的网络往往更难被训练，因此提出残差学习模块，在简化网络训练的同时，加深网络的深度，可以达到152层。
Introduction  深度卷积神经网络为图像分类带来了一系列突破。深度神经网络以端到端、多层的方式集成了由低到高的特征表示，并且特征的“级别”可以通过堆叠层的数量（深度）来增加。有研究表明，网络深度是至关重要的。
深度增加的同时，会带来一个问题，即梯度消失/爆炸。然而，这个问题已经被归一化初始化和中间归一化层所解决，这使得具有几十层的网络开始收敛于反向传播的随机梯度下降(SGD)。
当更深层次的网络能够开始收敛时，出现网络退化的问题，即随着网络深度的增加，精度达到饱和，然后迅速下降。但这种网络退化不是由过拟合引起的，是由于在适当的深度模型中添加更多的层会导致更高的训练误差。
训练精度的下降表明，并不是所有的结构都同样容易进行优化。通过构造更深的模型，有一个解决方案：增加的层是恒等映射（ identity mappings），而其他层是从浅层复制过来的。这表明，一个更深的模型不会比它较浅的模型产生更高的训练误差。
在本文中，引入深度残差学习框架解决网络退化问题，我们不是希望每几个堆叠层直接匹配所需的映射$H(x)$，而是匹配$F(x)$的另一个映射，即残差映射$H(x)-x$，那么原始的映射就变成了$F(x)+x$。在极端情况下，如果一个恒等映射是最优的，那么将残差推到零要比用一堆非线性层来拟合一个恒等映射更容易。
公式$F(x)+x$可用Shortcut Connection实现，并且Shortcut Connection只需实现恒等映射，既不增加额外参数也不增加计算量。
我们在ImageNe上进行了全面的实验来证明退化问题，并评估我们的方法，得到：（1）深度残差网很容易优化，但对应的“普通”网络（简单的堆叠层）表现出更高的训练误差；（2）深度残差网可以很容易地从大大增加的深度中获得精度，产生的结果比以前的网络更好得多
Related Work Residual Representations  残差表示作为一种重构或预处理方法是有效的。首先，在图像识别任务中的VLAD （矢量量化），有研究表明编码残差矢量比编码原始矢量更有效；其次，在低级视觉和计算机图形学中，需要求解部分微分方程，也被证明这些求解器比没有考虑残差性质的标准求解器收敛得快得多。
Shortcut Connections  训练多层感知机（MLP）的早期实践是添加一个线性层来连接网络的输入和输出。在一些研究中，某些中间层直接连接到辅助分类器，用于解决梯度消失/爆炸（如GoogleNet）。
同时，Highway Networks（下图）实现了带有门控单元的shortcut connection，需要参数控制，而 ResNet没有，这样就不会增加额外参数。（Highway Networks相当于对输入一部分进行处理（和传统神经网络相同），一部分直接通过）另外Highway Networks并没有精度与网络深度的显著提高（没有超过100层）。 Deep Residual Learning Residual Learning  假设存在映射$H(x)$，我们不是期望堆叠的层映射近似$H(x)$，而是让这些层近似于一个残差函数$F(x):=H(x)-x$。原来的映射就变成了$F(x)+x$，虽然这两种形式都应该能够渐近地近似于所期望的函数，但从之前的研究可以看出，其学习的容易程度可能是不同的，残差收敛速度更快并且效果更好。（其主要思想是将堆叠的非线性层从，拟合原来的最优解映射输出$H(x)$，变成去，拟合输出和输入的差$F(x) = H(x) - x$，此时原最优解映射$H(x)$就可以改写成$F(x) + x$。而作者认为这两种表达的效果相同，但是优化的难度却并不相同，）
正如之前说的那样，如果增加的层可以构造成恒等映射，那么更深的模型的训练误差应该不大于对应较浅的模型。而通过多个非线性层逼近恒等映射是存在困难的，因此，通过残差学习重构，如果恒等映射是最优的，模型就可以简单地将多个非线性层的权值（即$F(x)$）推向零，以接近恒等映射。但在实际情况下，恒等映射不太可能是最优的。
Identity Mapping by Shortcuts  残差块的公式定义和结构图如下所示： $$ y=F(x,\lbrace W_{i} \rbrace)+x $$ 其中，$x$和$y$是输入与输出，函数$F(x,\lbrace W_{i} \rbrace)$是要学习的残差映射。对应图中的两层的例子。$x$和$F(X)$通过Shortcut Connection和元素级相加实现的。公式中的Shortcut Connection不会引入额外的参数也不引入计算复杂度。同时$x$和$F(X)$的维度必须相同，如果不相同，通过$W_{s}$实现维度匹配： $$ y=F(x,\lbrace W_{i} \rbrace)+W_{s}x $$ 残差函数$F$的形式是灵活的。本文实验涉及两层或三层的函数$F$，也可能有更多的层。但如果只有一层，类似于线性层：$y=W_{1}x+x$，，从实验可以看出没有效果。</description>
    </item>
    
    <item>
      <title>GoogleNet</title>
      <link>https://gdy0924.github.io/posts/googlenetpaper/</link>
      <pubDate>Wed, 30 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/googlenetpaper/</guid>
      <description>GoogLeNet获得了2014年ILSVRC比赛分类任务的冠军，其利用Inception模块，在加深网络深度的同时，减少了参数量，从而减少计算资源的利用。
GoogLeNetV1 原文链接：GoogleNetV1
Abstract  提出一种名为“Inception”的深度卷积神经网络架构，可以增加网络的深度和宽度，同时保持计算量不变，从而提高网络精度。
Introduction  随着深度学习的发展，卷积网络在图像领域发展迅速，算法的效率，特别是计算量和内存的使用，变得越来越重要，在该网络中，我们也考虑到了这一方面。我们提出了一种更加高效的深度神经网络架构，名为“Inception module”，直接增加了网络的深度。
Motivation and High Level Considerations  提高深度神经网络性能的最直接的方法是增加网络的规模，包括：网络的深度（层数）和宽度（每一层的单元数量）。但存在两个问题：
（1）更大的尺寸通常意味着大量的参数，这使得扩大后的网络更容易发生过拟合，特别是在训练集有限的情况下；
（2）网络的扩大伴随着计算资源的使用显著增加，如果增加的部分使用效率较低（例如，如果大多数权重最终接近于零），那么就会浪费大量的计算。
解决上述问题的根本方法是：将完全连接转换成稀疏连接，一方面模拟了生物系统，另一方面，有研究证明了稀疏网络的有效性。
之前的研究为了打破网络对称性和提高学习能力，都使用了随机稀疏连接，但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新使用了全连接层，目的是为了更好地优化并行运算。
因此，需要一种网络结构，既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能，提出“Inception”结构来实现此目的。
Architectural Details 上图是提出的最原始的基本结构：
（1）采用不同大小的卷积核实现不同大小的感受野，在模块最后进行拼接实现不同尺度特征的融合；
（2）卷积核大小采用1、3和5，是为了方便对齐，即在设定卷积步长stride=1后，只要分别设定padding=0、1、2，不同卷积核操作之后得到的特征图大小就相同，方面最后的拼接操作；
（3）由于pooling操作被证明很有效，因此引入了池化分支；
（4）网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例会增加。
上述模块存在一个大问题，在该结构中，即使具有大量卷积核的卷积层中，少量的5×5卷积也会带来巨大的计算量，并且由于卷积结果与池化结果进行合并，因此从上一个模块到下一个模块，输出通道肯定要增加。
因此提出了改进的模块，在计算量大的地方引入降维操作，即在3×3和5×5卷积操作之前，先利用1×1卷积进行通道数的减少，从而减少网络参数，在减少计算量的同时，做一定的正则化，同时还引入了更多的非线性变换。改进的模块如下所示： 该结构的好处是：
（1）允许在每个阶段显著增加单元的数量，而不会导致计算复杂性的不受控制的爆炸；
（2）与直觉相一致，即视觉信息应该在不同的尺度上进行处理，然后进行聚合，以便下一阶段可以同时从不同的尺度上提取特征。
GoogLeNet 上图为完整的GoogLeNet网络结构，由于技术的原因，先进行传统的卷积层，只在较高的层开始使用Inception模块，其特点如下：
（1）该网络有22层深（如果加上池化层，是27层）；
（2）实验发现，用平均池化代替全连接层能够提高精度，因此使用了average pooling，同时使用dropout，但是依旧在网络最后添加了一个额外的全连接层，主要是为了更加方便地调整和微调网络；
（3）由于网络的深度相对较大，因此需要解决梯度回传的问题，在网络中间的层，额外添加了两个辅助的softmax用于向前传导梯度，在训练过程中，它们的损失以折扣权值加到网络的总损失中（辅助分类器的损失加权为0.3），在测试时这两个额外的softmax会被去掉，辅助分类器的结构如下：
（a）5×5大小的平均池化，stride=3；
（b）1×1×128卷积操作，用于降维和非线性激活； （c）1024个神经元的全连接层； （d）p=70%的Dropout； （e）以Softmax损失作为分类器的线性层，分类数为1000。
Conclusions  通过构建密集的块结构来近似最优的稀疏结构，从而达到提高性能而又不大量增加计算量的目的，是一个可行的方法，通过实验也证明了Inception模块的优势。
GoogleNetV2 原文链接：GoogleNetV2
Inception V2学习了VGGNet，用两个3×3的卷积代替5×5的大卷积（用以降低参数量并减轻过拟合），还提出了著名的BatchNormalization方法。BN是一个非常有效的正则化方法，可以让大型卷积网络的训练速度加快很多倍，同时收敛后的分类准确率也可以得到大幅提高（详见BatchNormalization）。
GoogleNetV3 原文链接：GoogleNetV2
General Design Principles  提出一些基于使用卷积网络的各种架构选择的设计原则，包含一定的推测，不过经过实验证明基本是有效的：
（1）avoid representational bottlenecks 避免表征瓶颈：（特别是在网络浅层）信息流前向传播过程中显然不能经过高度压缩的层，即表征瓶颈，从输入到输出，特征图的宽和高基本都会逐渐变小，但是不能一下子就变得很小；
（2）higher dimensional representations 高维特征： 高维特征更容易区分和处理，从而会加快训练；
（3）spatial aggregation 空间聚合： 空间聚合可以在低维嵌入上进行，而不会造成太多或任何表征能力的损失，同时还可以提高速度，比如在进行3x3卷积之前，可以对输入先进行降维而不会产生严重的后果；</description>
    </item>
    
    <item>
      <title>Open World Object Detector</title>
      <link>https://gdy0924.github.io/posts/open-world-object-detector/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/open-world-object-detector/</guid>
      <description>原文链接：ORE
Abstract  开放世界对象检测（Open World Object Detector）模型的任务是：识别未知的（unknown）对象， 即没有明确监督标签；当相应的标签逐步被接收到时，可学习到未知对象的类别，并且不忘记之前学习到的标签。以上是该论文提出的问题，并引入了一个新的模型：ORE（Open World Object Detector），该模型基于对比聚类和基于能量的位置对象识别。
Introduction  深度学习中目标检测任务是识别和定位图像中的物体。现有的研究都有一个强有力的假设：要检测的所有类别都在训练阶段给出。当上述假设不存在，那么就有两个具有挑战性的问题：测试图像可能包含未知类别，这些对象应被归为未知类（unknown）；当关于未知类别的对象信息可用时，模型应该逐步学习这些新的类别。该论文提出了一个新的问题：一个模型应该能够将未知对象识别为未知类，在训练数据阶段以统一的方式逐步学习和识别他们。
contributions 1、引入一个新的问题Open World Object Detector；
2、提出一种新方法ORE，基于对比聚类，一个未知提议网络和基于能量的未知类识别；
3、提出一个新的全面的实验设置；
4、所提出的方法在增量目标检测上取得了最优异的成绩。
Related Work Open Set Classification  虽然这种模型可以识别出未知的实例，但它们不能在多个训练过程中以增量的方式动态地更新自己，即无法学习未知类别。
Open World Classification  这种模型可以识别已知类和未知类的对象，并在提供未知的新标签时自适应地改进自己，但是他们没有在图像分类基准上进行测试。
Open Set Detection  一些研究发现传统物体检测模型经常将未知类别的物体识别成已知的某一类别，因此其处理方式通常为：1. 新增一个background类别 2. 去除未知类别的物体。但是上述两个方法都不能在真实动态环境中使用。
Open World Object Detection  在任意时刻$t$，我们已知类别表示为$K^{t}= \lbrace 1,2,&amp;hellip;,C \rbrace \subset N^{+}$（共$C$个类别），其中$N^{+}$代表正整数的集合，同时假设存在一组未知类别$U=\lbrace C+1,&amp;hellip; \rbrace$，在推理过程中可能会遇到。已知类别$K_{t}$在数据集$D^{t}=\lbrace X^{t},Y^{t} \rbrace$中被标记，其中$X$、$Y$分别表示输入图像和标签。输入图像集由$M$张训练图像组成，$X^{t}=\lbrace I_{1},&amp;hellip;,I_{M} \rbrace$以及每张图像对应的标签集$Y^{t}=\lbrace Y_{1},&amp;hellip;,Y_{M} \rbrace$。每个$Y_{i}=\lbrace y_{1},y_{2},&amp;hellip;,y_{K} \rbrace$代表$K$个对象实例的类别标签和定位（即一张图像上有$K$个被标记的对象实例），并且$y_{k}=\left [ l_{k},x_{k},y_{k},w_{k},h_{k} \right ]$，其中$l_{k}$代表类别，$ x_{k}$，$y_{k}$、$w_{k}$、$h_{k}$分别代表 bounding box的中心坐标、宽和高。</description>
    </item>
    
    <item>
      <title>VGG</title>
      <link>https://gdy0924.github.io/posts/vggpaper/</link>
      <pubDate>Tue, 29 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/vggpaper/</guid>
      <description>原文链接：VGG
VGG网络获得了2014年ILSVRC比赛的分类任务的亚军和定位任务的冠军，其主要贡献是通过更小的卷积核堆叠构建更深层的网络。 Abstract  该论文研究了卷积网络深度对精度的影响，通过使用小的卷积核（大小为3×3）加深网络的深度，将深度增加到了16-19层，并取得了不错的效果。
Introduction  卷积神经网络在大规模图像核视频识别方面取得了巨大成功。在该论文中，我们关注卷积网络的另一个方面——网络的深度。通过添加更多的卷积层来增加网络的深度，并且使用的卷积核大小很小。
ConvNet Configurations Architecture  输入为224×224大小的RGB图像，每层都使用3×3大小的卷积核提取特征，固定步长为1，填充为1，以保证卷积前后的特征图大小相同。最大池化的大小为2×2，步长也为2，即特征图缩小一半，并且不是所有的卷积层后边都跟池化层。
卷积层后跟着三个全连接层，前两个有4096个通道，最后一个有1000个通道（因为比赛中的类别数是1000），最后一层是Softmax层。
每一层后都跟着非线性激活层，并且我们没有用到（除了一个架构）AlexNet所提出的LRN层，通过实验发现LRN层并没有提高ILSVRC数据集上的性能，但却导致了内存消耗和计算时间的增加。
Configurations 从图中可以看出，不同网络的架构是相同的，除了深度不同，从11层的网络（8层卷积和3个FC层）到19层网络（16层卷积和3个FC层）。通道数由最开始的64，每次操作都使通道数增加一倍，直到512层。由于卷积核小，因此虽然网络很深，但其网络参数没有很多。
Discussion  不同于之前的网络，我们没有在网络第一层使用较大的感受野，如11×11或7×7，而是利用小的感受野（大小为3×3）贯穿整个网络结构。可以看出，两个3×3大小的感受野堆叠起来的感受野与一个5×5大小的感受野相同，三个3×3大小的感受野堆叠起来的感受野与一个7×7大小的感受野相同。使用三个3×3大小的感受野代替一个7×7大小的感受野的好处有：（1）三层感受野就引入了三次非线性变换，因此增加了网络的非线性表达能力；（2）三个3×3大小的感受野共有27个参数，而一个7×7大小的感受野有49个参数，因此可以减少网络的参数数量，可以看作对网络做了相应的正则化。
在16层的网络中，我们使用得到了1×1的卷积核，在不改变感受野的前提下增加了非线性，同时输入通道核输出通道是相同的。
GoogleNet与我们的相似之处就是它是基于较深的网络（22层）和小卷积核（除了3×3，他们还用到了1×1和5×5）。他们的网络结构比我们更加复杂 ，并且在第一层就将图像分辨率降低了很多，以减少计算量。
Classification Framework Training  使用具有动量的小批量梯度下降算法，Dropout，对输入图像进行随机剪裁、随机水平翻转和随机RGB颜色位移等操作。
考虑了两种训练图像尺寸S的方法：
（1）单尺寸训练：在实验中，使用两种尺寸大小验证模型，S=256和S=384。给定一个卷积网络，我们首先使用S=256训练网络。为了加快S=384网络的训练，我们使用S=256预训练的权值初始化；
（2）多尺寸训练：每个训练图像在一定范围内$\left [ S_{min},S_{max} \right ]$随机采样S，其中，$S_{min}=256,S_{max}=512$。我们通过微调单尺度模型来训练多尺度模型，并使用固定的S=384进行预训练。
Testing  在测试阶段，首先将输入图像缩放至最小的尺寸$Q$，同时$Q$并不一定等于训练中的$S$，在训练阶段，每个$S$对应的网络，使用多个不同的$Q$对其进行测试。接着将网络最后三层的全连接层改为卷积层，第一个FC层改为7×7×4096的卷积层，第二个改为1×1×4096，第三个改为1×1×1000，可以看出，最终的通道数对应的是分类数。通过改为卷积层，可以接受输入大小不同的图片，只是最终得到的特征图的大小不同，但其通道数依旧对应分类数，可以通过对最终的特征图进行空间平均（求和，sum-pooled）得到Softmax输入之前的分数。我们还通过图像的水平翻转来增加测试集，将原始图像和翻转图像的Softmax分数进行平均，以获得图像的最终分数。 Conclusion  提出了比较深的卷积网络（19个权重层）用于大尺度的图像分类，实验结果表明，更深层的网络有利于提高分类精度。</description>
    </item>
    
    <item>
      <title>Relevance-CAM</title>
      <link>https://gdy0924.github.io/posts/relevance-campaper/</link>
      <pubDate>Sun, 27 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/relevance-campaper/</guid>
      <description>原文链接：Relevance-CAM
Abstract  目前在深度学习的可解释性领域，一种主要的常见的是基于类激活映射(Class Activation Mapping, CAM)的方法，常用在卷积网络的最后一层。在本文中，提出了一种相关加权类激活映射(Relevance-weighted Class Activation Mapping, Relevance-CAM)，以解决基于梯度的CAM在梯度消失方面的问题，并且该方法在网络的任意一层都可以应用。
Introduction  随着深度神经网络的不断发展，可解释网络也被广泛研究，其方法主要分为基于类激活映射(CAM)的和基于分解的。基于CAM的方法通过全局平均池化得到每个通道的权重，接着利用最后一层卷积的特征图进行加权线性求和操作得到可视化的结果。但是该方法只能用在最后一层，且必须用到全局平均池化和全连接层。基于梯度的CAM，Grad-CAM和 Grad-CAM++ 对其进行改进，使用梯度作为权重。层相关性传播(Layer-wise Relevance Propagation, LRP)是基于分解的方法。LRP通过特定的传播规则将最终的输出分数向后传播，重新分配到输入图像中，从而解决了梯度消失的问题。 Contributions 1、提出了Relevance-CAM，解决了梯度消失的问题，同时在中间层也可以工作； 2、通过可视化热图，展示了我们所提出的方法优于其他方法； 3、通过Average Drop、Average Increase和Intersection over Union三种客观数值证明我们所提出的方法优于其他方法； 4、我们通过实验发现，即使在浅层，网络也可以提取到类特定信息。
Background CAM 原文链接：CAM 类激活映射(CAM)通过全局平均池化层获得权重，接着将最后一个卷积层的特征图进行线性加权求和，如下图所示。但是该方法有很大的局限性，只能用于最后一层的可视化，并且要在原网络的基础上增加全局平均池化层。 Grad-CAM 原文链接：Grad-CAM Grad-CAM改变了权重计算的方法，利用最后输出分数对某一层特征图的梯度作为权重，以解决CAM所存在的问题。 其计算公式如下：
$$ L_{Grad-CAM}^{c}=\sum_k\alpha _k^{c}A_k $$
$$ \alpha _k^{c}=GP\left ( \frac{\partial y^{c}}{\partial A_k} \right ) $$
其中，$ A_k $是第$ k $个通道的特征图，$ y^{c} $是类别$ c $对应的得分，$\alpha _{k}^{c}$ 代表权重，GP()表示全局平均函数。
Layer-wise Relevance Propagation(LRP) 原文链接：LRP LRP通过分层地将相关性分数从输出传播到输入图像，从而获得原始图像中每个像素的相关性分数，并且传播过程满足守恒且分数恒不小于零，如下所示： $$ \forall x:f_{c}\left ( x \right )=\sum_{p}R_{p}^{l}\left ( x \right ) $$</description>
    </item>
    
    <item>
      <title>AlexNet</title>
      <link>https://gdy0924.github.io/posts/alexnetpaper/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/alexnetpaper/</guid>
      <description>AlexNet在在2012年的ImageNet竞赛中取得了冠军，作为第一个深度卷积网络在该比赛中获得如此好的成绩，AlexNet证实了深度卷积网络的潜力，并引起了研究者们的极大热情。 AlexNet共包含8层，其中前5层为卷积层，后三层为全连接层，最后一个全连接层的输出是1000维，输入softmax产生最终的输出：1000类的标签分布。
原文链接：AlexNet
网络架构 输入层 输入图片的大小为224×224，并包含R、G、B三个通道。对于原始的数据，AlexNet进行了数据增强操作。
Layer1 输入图片：224×224×3（227×227×3） 卷积核：11×11×96 步长(stride)：4 填充(padding)：1 输出大小：54×54×96（55×55×96） 池化：size=3×3，stride =2, padding=0 第一个卷积层使用96个11×11的卷积核对图片进行特征提取，并且经过ReLU、LRN层和最大池化层得到第一层的输出，大小为27×27×96。
Layer2 输入图片：27×27×96 卷积核：5×5×256 步长(stride)：1 填充(padding)：2 输出大小：27×27×256 池化：size=3×3，stride =2, padding=0 第二个卷积层使用256个5×5的卷积核对图片进行特征提取，并且经过ReLU、LRN层和最大池化层得到第二层的输出，大小为13×13×256。
Layer3 输入图片：13×13×256 卷积核：3×3×384 步长(stride)：1 填充(padding)：1 输出大小：13×13×384 第三个卷积层使用384个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活得到第三层的输出，大小为13×13×384。
Layer4 输入图片：13×13×384 卷积核：3×3×384 步长(stride)：1 填充(padding)：1 输出大小：13×13×384 第四个卷积层使用384个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活得到第四层的输出，大小为13×13×384。
Layer5 输入图片：13×13×384 卷积核：3×3×256 步长(stride)：1 填充(padding)：1 输出大小：13×13×256 池化：size=3×3，stride =2, padding=0 第五个卷积层使用256个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活和池化层得到第五层的输出，大小为6×6×384。
全连接层 第6、7、8层都为全连接层，并且每层的神经元个数都为4096个，最后经过softmax得到最终1000个类别的分类结果。
Innovation创新点 ReLU非线性激活 AlexNet是第一个使用ReLU函数作为激活函数的网络，之前使用最多的激活函数是Sigmiod函数，函数图像如下所示。可以看出，Sigmiod函数在输入x的值很大或者很小的时候，其梯度非常小，几乎接近于0，那么在反向传播过程中，由于梯度的链式法则，就会导致网络的浅层得到的梯度为0，无法正常更新权重，因此AlexNet就提出可以使用ReLU函数来解决梯度消失的问题。ReLU函数在输入x大于0时，其梯度一直为1，解决了梯度消失问题，并且在输入x小于0时，输出为0，就使得网络更加稀疏，从而减少了参数的相互依存关系，缓解了过拟合问题。 多GPU 由于当时GPU内存的限制，AlexNet将网络放在2两GPU上进行训练，从网络架构图中可以看出，每一层都是将通道数一份为2，分别放在不同的GPU上，并且规定GPU只能在特定的层进行通信交流。
LRN 虽然使用ReLU函数不需要再进行标准化，不过实验表明局部响应标准化(Local Response Normalization)有助于泛化。其公式如下： $$ b_{x,y}^{i}=a_{x,y}^{i}/\left ( k+\alpha \sum_{j=max\left ( 0,i-n/2 \right )}^{min\left ( N-1,i+n/2 \right )}\left ( a_{x,y}^{j} \right )^{2}\right )^{\beta } $$ 其中, $ a_{x,y}^{i} $表示经过激活函数ReLU得到的特征图对应位置为(x,y)的输出值，$ b_{x,y}^{i} $ 表示经过LRN后的输出值，$ N $ 为卷积核的个数，$k$、$n$、$\alpha$、$\beta$为超参数，在该论文中设置的分别为：$k=2$，$n=5$，$\alpha=10^{-4}$，$\beta=0.</description>
    </item>
    
    <item>
      <title>LeNet</title>
      <link>https://gdy0924.github.io/posts/lenetpapar/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/lenetpapar/</guid>
      <description>LeNet是很简单的一个经典卷积神经网络，主要用于手写数字识别，所以是一个多分类任务，并且是十个类别。该网络架构如下图所示，每一层分别是卷积层、池化层、卷积层、池化层、卷积层和全连接层，最后连接Softmax实现分类。
原文链接：LeNet
网络架构 输入层 将输入图像的尺寸统一归一化为32×32×1，其中第一个32代表图片的高度，第二个32代表图片的宽度，1是指通道数，由于对应的数据集是黑白的，所以其通道数为1，对于彩色的图片，通道数为3，分别对应R、G、B。
第一层：卷积层 输入图片：32×32×1 卷积核：5×5×6 步长：1 输出大小：28×28×6 神经元数量：28×28×6 参数个数：(5×5+1)×6 第一层为卷积层，使用6个大小为5×5的卷积核，提取图片的feature map，得到6个大小为28×28的feature map。
第二层：池化层 输入：28×28×6 核大小：2×2×6 步长：2 输出大小：14×14×6 神经元数量：14×14×6 参数个数：2×6 通过池化层对图像进行下采样，在该层采用的是最大池化，即选择区域中的最大值作为采样的值，除了最大池化外，还有平均池化等。
第三层：卷积层 输入图片：14×14×6 卷积核：5×5×16 步长：1 输出大小：10×10×16 参数：6×(3×5×5+1)+6×(4×5×5+1)+3×(4×5×5+1)+1×(6××5+1) 该层使用16个大小为5×5的卷积核，对大小为14×14、通道数为6的feature map进行卷积，，最终得到16个大小为10×10的feature map。 对于该层的16个卷积核，其中前六个与上一层的相连三个feature map相对应，接着六个卷积核与上一层的相连四个feature map相对应，接下来的三个与上一层的部分不相连的四个feature map相对应，最后一个卷积核与上一层得到的所有feature map对应。
第四层：池化层 输入：10×10×16 核大小：2×2×16 步长：2 输出大小：5×5×16 神经元数量：5×5×16 参数：2×16 对16个10×10大小的feature map进行最大池化，得到16个大小为5×5的feature map。
第五层：卷积层 输入图片：5×5×16 卷积核：5×5×120 步长：1 输出大小：1×1×120 神经元数量：28×28×6 参数：(16×5×5+1)×120 该层使用120个大小为5×5的卷积核，对图片进行卷积操作，得到120个大小为1×1的feature map。
第六层：全连接层 输入大小：120 输出大小：84 该层为全连接层，共有84个神经元。
输出层 输入大小：84 输出大小：10 该层为全连接层，包含10个神经元，对应最后的十个分类情况。
特点 在S2与C3之间，输入的feature map和输出的feature map之间并不是全连接的，而是局部连接的，如图所示。其中行对应的是C3的feature map，列对应的是S2的feature map。以第0列为例，C3的第一个feature map是由S2的前三个feature map经过卷积核操作得到的，而C3的第七个feature map，也就是第6列，是由S2的前四个feature map经过卷积核操作得到的。 </description>
    </item>
    
  </channel>
</rss>
