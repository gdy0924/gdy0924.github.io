<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on XY&#39;s Blog</title>
    <link>https://gdy0924.github.io/posts/</link>
    <description>Recent content in Posts on XY&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Mar 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://gdy0924.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ResNet（待补充）</title>
      <link>https://gdy0924.github.io/posts/resnet1/</link>
      <pubDate>Tue, 15 Mar 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/resnet1/</guid>
      <description>本周的人工智能课程的实验是在华为云平台上搭建网络并训练，实现图片分类。该实验的baseline是残差网络ResNet，所以对该网络进行了简单的学习，并且研究了其代码实现，并对ResNet的改进进行了上网查询。
原文链接：ResNet
残差结构 当网络的深度增加时，应当可以提取更多更深的图片特征，所以准确率应该提高，但是实际上，随着网络的增加，准确率会先增加，达到最大之后，会出现降低的现象。由于梯度爆炸和梯度消失的问题，导致深层的网络不好训练，所以提出了残差结构，即希望在深层的网络中实现恒等映射，最差的情况也是这些层什么也不学习，至少不会带来退化的问题。残差结构如图所示： 可以看出，是在普通的网络结构上，添加了一条从输入直接到输出的直接路径，将输入与经过卷积的输出进行连接，传入下一层网络中。 当输入和输出维度不一样时，这就不能直接相加，这时有两种方法 （1）使用零填充控制feature map的大小，一般要先做一个下采样，可以采用strde=2的池化，该方法不会增加参数； （2）使用1×1的卷积来升维或者降采样，该方法会增加参数，也会增加计算量。
ResNet ResNet使用了两种残差单元，分别是两层间的残差学习和三层间的残差学习，如下图所示，浅层网络ResNet-18和ResNet-34使用的是第一种残差结构，而深层的网络ResNet-50、ResNet-101和ResNet-152使用的是第二种。 上述五种ResNet网络结构如下图所示： 改进 小卷积代替大卷积 3×3的卷积核核7×7的卷积核他们的感受野是不同的，相比更大的感受野，更小的感受野可以捕捉到更为细致的信息。并且两个3×3的堆叠卷积层的感受野是5×5，三个3×3的堆叠卷积层的感受野是7×7，所以可以使用3个3×3的卷积核代替ResNet第一步的7×7卷积核。另外，使用多个卷积核也使用了更多的非线性激活函数，带来更大的非线性。
修改残差内部结构 ResNet V2是对ResNet的改进，如图所示。研究者们对残差结构中的各个部分进行了调整位置、变换等操作，并经过一系列的实验，得出了改进后性能最好的结构。由图可以看出，改进前后一个明显的变化是采用pre-activation，即将非线性激活函数提前到卷积操作之前，同时BN也提前，在最后输出和输出相加之后，不再进行激活操作。 </description>
    </item>
    
    <item>
      <title>BatchNormalization</title>
      <link>https://gdy0924.github.io/posts/batchnormalization/</link>
      <pubDate>Mon, 24 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/batchnormalization/</guid>
      <description>批归一化主要用在非线性激活函数层前，它不仅可以加快模型训练时的收敛速度，而且还能够使模型训练过程更加稳定，避免梯度爆炸或者梯度消失，也起到一定的正则化作用，所以在目前的网络中被广泛使用到。
计算步骤及公式 1、计算均值与方差 首先，对于输入的数值集合$ B= $ $\lbrace$ $ x_{1&amp;hellip;m} $ $\rbrace$，计算其均值$ \mu _{B} $和方差$ \sigma _{B}^{2} $，如下所示： $$ \mu _{B}=\frac{1}{m} \sum_{i=1}^{n} {x_i} $$
$$ \sigma _{B}^{2} = \frac{1}{m} \sum_{i=1}^{m} (x_i- \mu _{B})^{2} $$
2、数据标准化 将集合$ B $转化为均值为0、方差为1的正态分布$ \tilde{x_{i}} $，其中$ \epsilon $是引入的一个极小常数，以防止在公式中出现除零的情况 $$ \tilde{x_{i}}=\frac{x_{i}-\mu _{B}}{\sqrt{\sigma _{B}^{2}+\epsilon }} $$
3、BN 引入可训练参数$ \gamma $和$ \beta $，对数据实现平移和缩放操作，通过引入的两个还原参数，可以使网络学习到原始的特征分布，在一定程度上保留了原始数据的分布 $$ y_{i}=\gamma \tilde{x_{i}}+\beta
$$
在全连接层中，BN作用在特征维上，而在卷积层中，BN作用在通道维上，具体来说，就是对feature map的通道方向求均值和方差，即假设batch size=n, feature map的shape= (w, h, c), 则会对c个$nwh $的特征分别求出c个均值和方差。
预测阶段的BN 在训练阶段，可能没有许多的数据来形成一整个batch，可能只用单个数据来进行测试，这时，单个数据就无法计算上边公式中的均值与方差。 在训练阶段，针对每一个batch使用BN公式计算出的均值 $ \mu= $ $\lbrace$ $\mu ^{1},\mu ^{2},&amp;hellip;,\mu ^{n} $ $\rbrace$ 和 $ \sigma =$ $\lbrace$ $\sigma ^{1},\sigma ^{2},&amp;hellip;,\sigma ^{n} $ $\rbrace$ ，分别计算，其中$ p $是新引入的可调节参数。 $$ \bar{\mu }=p\bar{\mu }+\left ( 1-p \right )\mu ^{t} $$</description>
    </item>
    
    <item>
      <title>AlexNet</title>
      <link>https://gdy0924.github.io/posts/alexnetcode/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/alexnetcode/</guid>
      <description>AlexNet在在2012年的ImageNet竞赛中取得了冠军，作为第一个深度卷积网络在该比赛中获得如此好的成绩，AlexNet证实了深度卷积网络的潜力，并引起了研究者们的极大热情。 AlexNet共包含8层，其中前5层为卷积层，后三层为全连接层，最后一个全连接层的输出是1000维，输入softmax产生最终的输出：1000类的标签分布。
实现 基于pytorch实现的代码如下：
1 2import torch 3from torch import nn 4from d2l import torch as d2l 5 6net = nn.Sequential( 7 nn.Conv2d(1,96,kernel_size=11,stride=4,padding=1),nn.ReLU(), 8 nn.MaxPool2d(kernel_size=3,stride=2), 9 nn.Conv2d(96,256,kernel_size=5,padding=2),nn.ReLU(), 10 nn.MaxPool2d(kernel_size=3,stride=2), 11 nn.Conv2d(256,384,kernel_size=3,padding=1),nn.ReLU(), 12 nn.Conv2d(384,384,kernel_size=3,padding=1),nn.ReLU(), 13 nn.Conv2d(384,256,kernel_size=3,padding=1),nn.ReLU(), 14 nn.MaxPool2d(kernel_size=3,stride=2),nn.Flatten(), 15 nn.Linear(6400,4096),nn.ReLU(),nn.Dropout(p=0.5), 16 nn.Linear(4096,4096),nn.ReLU(),nn.Dropout(p=0.5), 17 nn.Linear(4096,10)) 18 19X = torch.randn(1,1,224,224) 20for layer in net: 21 X=layer(X) 22 print(layer.__class__.__name__,&amp;#39;output shape:\t&amp;#39;,X.shape) 23 24batch_size=128 25train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size,resize=224) 26 27def evaluate_accuracy_gpu(net,data_iter,device=None): 28 if isinstance(net, nn.Module): 29 net.eval() 30 if not device: 31 device = next(iter(net.</description>
    </item>
    
    <item>
      <title>AlexNet</title>
      <link>https://gdy0924.github.io/posts/alexnetpaper/</link>
      <pubDate>Wed, 12 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/alexnetpaper/</guid>
      <description>AlexNet在在2012年的ImageNet竞赛中取得了冠军，作为第一个深度卷积网络在该比赛中获得如此好的成绩，AlexNet证实了深度卷积网络的潜力，并引起了研究者们的极大热情。 AlexNet共包含8层，其中前5层为卷积层，后三层为全连接层，最后一个全连接层的输出是1000维，输入softmax产生最终的输出：1000类的标签分布。
原文链接：AlexNet
网络架构 输入层 输入图片的大小为224×224，并包含R、G、B三个通道。对于原始的数据，AlexNet进行了数据增强操作。
Layer1 输入图片：224×224×3（227×227×3） 卷积核：11×11×96 步长(stride)：4 填充(padding)：1 输出大小：54×54×96（55×55×96） 池化：size=3×3，stride =2, padding=0 第一个卷积层使用96个11×11的卷积核对图片进行特征提取，并且经过ReLU、LRN层和最大池化层得到第一层的输出，大小为27×27×96。
Layer2 输入图片：27×27×96 卷积核：5×5×256 步长(stride)：1 填充(padding)：2 输出大小：27×27×256 池化：size=3×3，stride =2, padding=0 第二个卷积层使用256个5×5的卷积核对图片进行特征提取，并且经过ReLU、LRN层和最大池化层得到第二层的输出，大小为13×13×256。
Layer3 输入图片：13×13×256 卷积核：3×3×384 步长(stride)：1 填充(padding)：1 输出大小：13×13×384 第三个卷积层使用384个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活得到第三层的输出，大小为13×13×384。
Layer4 输入图片：13×13×384 卷积核：3×3×384 步长(stride)：1 填充(padding)：1 输出大小：13×13×384 第四个卷积层使用384个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活得到第四层的输出，大小为13×13×384。
Layer5 输入图片：13×13×384 卷积核：3×3×256 步长(stride)：1 填充(padding)：1 输出大小：13×13×256 池化：size=3×3，stride =2, padding=0 第五个卷积层使用256个3×3的卷积核对图片进行特征提取，并且经过ReLU非线性激活和池化层得到第五层的输出，大小为6×6×384。
全连接层 第6、7、8层都为全连接层，并且每层的神经元个数都为4096个，最后经过softmax得到最终1000个类别的分类结果。
Innovation创新点 ReLU非线性激活 AlexNet是第一个使用ReLU函数作为激活函数的网络，之前使用最多的激活函数是Sigmiod函数，函数图像如下所示。可以看出，Sigmiod函数在输入x的值很大或者很小的时候，其梯度非常小，几乎接近于0，那么在反向传播过程中，由于梯度的链式法则，就会导致网络的浅层得到的梯度为0，无法正常更新权重，因此AlexNet就提出可以使用ReLU函数来解决梯度消失的问题。ReLU函数在输入x大于0时，其梯度一直为1，解决了梯度消失问题，并且在输入x小于0时，输出为0，就使得网络更加稀疏，从而减少了参数的相互依存关系，缓解了过拟合问题。 多GPU 由于当时GPU内存的限制，AlexNet将网络放在2两GPU上进行训练，从网络架构图中可以看出，每一层都是将通道数一份为2，分别放在不同的GPU上，并且规定GPU只能在特定的层进行通信交流。
LRN 虽然使用ReLU函数不需要再进行标准化，不过实验表明局部响应标准化(Local Response Normalization)有助于泛化。其公式如下： $$ b_{x,y}^{i}=a_{x,y}^{i}/\left ( k+\alpha \sum_{j=max\left ( 0,i-n/2 \right )}^{min\left ( N-1,i+n/2 \right )}\left ( a_{x,y}^{j} \right )^{2}\right )^{\beta } $$ 其中, $ a_{x,y}^{i} $表示经过激活函数ReLU得到的特征图对应位置为(x,y)的输出值，$ b_{x,y}^{i} $ 表示经过LRN后的输出值，$ N $ 为卷积核的个数，$k$、$n$、$\alpha$、$\beta$为超参数，在该论文中设置的分别为：$k=2$，$n=5$，$\alpha=10^{-4}$，$\beta=0.</description>
    </item>
    
    <item>
      <title>LeNet</title>
      <link>https://gdy0924.github.io/posts/lenetcode/</link>
      <pubDate>Sun, 26 Dec 2021 20:58:21 +0800</pubDate>
      
      <guid>https://gdy0924.github.io/posts/lenetcode/</guid>
      <description>LeNet是很简单的一个经典卷积神经网络，主要用于手写数字识别，所以是一个多分类任务，并且是十个类别。
实现 基于pytorch实现的代码如下：
1 2import torch 3from torch import nn 4from d2l import torch as d2l 5 6class Reshape(torch.nn.Module): 7 def forward(self,x): 8 return x.view(-1,1,28,28) 9 10net = torch.nn.Sequential( 11 Reshape(),nn.Conv2d(1,6,kernel_size=5,padding=2),nn.Sigmoid(), 12 nn.AvgPool2d(kernel_size=2,stride=2), 13 nn.Conv2d(6,16,kernel_size=5),nn.Sigmoid(), 14 nn.AvgPool2d(kernel_size=2,stride=2),nn.Flatten(), 15 nn.Linear(16*5*5,120),nn.Sigmoid(), 16 nn.Linear(120,84),nn.Sigmoid(), 17 nn.Linear(84,10)) 18 19X = torch.rand(size=(1,1,28,28),dtype=torch.float32) 20for layer in net: 21 X = layer(X) 22 print(layer.__class__.__name__,&amp;#39;output shape：\t&amp;#39;,X.shape) 23 24batch_size=256 25train_iter,test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size) 26 27def evaluate_accuracy_gpu(net,data_iter,device=None): 28 if isinstance(net, nn.Module): 29 net.</description>
    </item>
    
    <item>
      <title>LeNet</title>
      <link>https://gdy0924.github.io/posts/lenetpapar/</link>
      <pubDate>Sun, 26 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/lenetpapar/</guid>
      <description>LeNet是很简单的一个经典卷积神经网络，主要用于手写数字识别，所以是一个多分类任务，并且是十个类别。该网络架构如下图所示，每一层分别是卷积层、池化层、卷积层、池化层、卷积层和全连接层，最后连接Softmax实现分类。
原文链接：LeNet
网络架构 输入层 将输入图像的尺寸统一归一化为32×32×1，其中第一个32代表图片的高度，第二个32代表图片的宽度，1是指通道数，由于对应的数据集是黑白的，所以其通道数为1，对于彩色的图片，通道数为3，分别对应R、G、B。
第一层：卷积层 输入图片：32×32×1 卷积核：5×5×6 步长：1 输出大小：28×28×6 神经元数量：28×28×6 参数个数：(5×5+1)×6 第一层为卷积层，使用6个大小为5×5的卷积核，提取图片的feature map，得到6个大小为28×28的feature map。
第二层：池化层 输入：28×28×6 核大小：2×2×6 步长：2 输出大小：14×14×6 神经元数量：14×14×6 参数个数：2×6 通过池化层对图像进行下采样，在该层采用的是最大池化，即选择区域中的最大值作为采样的值，除了最大池化外，还有平均池化等。
第三层：卷积层 输入图片：14×14×6 卷积核：5×5×16 步长：1 输出大小：10×10×16 参数：6×(3×5×5+1)+6×(4×5×5+1)+3×(4×5×5+1)+1×(6××5+1) 该层使用16个大小为5×5的卷积核，对大小为14×14、通道数为6的feature map进行卷积，，最终得到16个大小为10×10的feature map。 对于该层的16个卷积核，其中前六个与上一层的相连三个feature map相对应，接着六个卷积核与上一层的相连四个feature map相对应，接下来的三个与上一层的部分不相连的四个feature map相对应，最后一个卷积核与上一层得到的所有feature map对应。
第四层：池化层 输入：10×10×16 核大小：2×2×16 步长：2 输出大小：5×5×16 神经元数量：5×5×16 参数：2×16 对16个10×10大小的feature map进行最大池化，得到16个大小为5×5的feature map。
第五层：卷积层 输入图片：5×5×16 卷积核：5×5×120 步长：1 输出大小：1×1×120 神经元数量：28×28×6 参数：(16×5×5+1)×120 该层使用120个大小为5×5的卷积核，对图片进行卷积操作，得到120个大小为1×1的feature map。
第六层：全连接层 输入大小：120 输出大小：84 该层为全连接层，共有84个神经元。
输出层 输入大小：84 输出大小：10 该层为全连接层，包含10个神经元，对应最后的十个分类情况。
特点 在S2与C3之间，输入的feature map和输出的feature map之间并不是全连接的，而是局部连接的，如图所示。其中行对应的是C3的feature map，列对应的是S2的feature map。以第0列为例，C3的第一个feature map是由S2的前三个feature map经过卷积核操作得到的，而C3的第七个feature map，也就是第6列，是由S2的前四个feature map经过卷积核操作得到的。 </description>
    </item>
    
    <item>
      <title>模型评价指标</title>
      <link>https://gdy0924.github.io/posts/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</link>
      <pubDate>Sat, 11 Dec 2021 15:52:51 +0800</pubDate>
      
      <guid>https://gdy0924.github.io/posts/%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BB%B7%E6%8C%87%E6%A0%87/</guid>
      <description>对于训练好的模型，我们通常更加关注该模型在未知数据上的性能“好坏”，也就是模型的泛化能力如何。要对模型的泛化性能进行评估，就需要有衡量模型泛化能力的评价标准，即评价指标，或者称为性能度量。针对两种不同的任务类型：分类任务和回归任务，有各自不同的评价指标。
回归任务 回归任务简单来说就是对连续值进行预测，比如：面积大小、数量多少等，最常用的性能度量是平均绝对误差(MAE)和均方误差(MSE)。
MAE 平均绝对误差就是计算预测值与真实值之间的距离，公式如下：
$$ MAE=\frac{1}{n}\sum_{i=1}^{n}\left | y_{i}-\hat{y_{i}} \right | $$
MSE 均方误差就是计算预测值与真实值之间距离的平方和，公式如下：
$$ MSE=\frac{1}{n}\sum_{i=1}^{n}\left ( y_{i}-\hat{y_{i}} \right )^{2} $$
分类任务 分类任务简单来说就是对离散值进行预测，比如是不是、属不属于、或者属于哪一类，最常用的性能度量是准确率、错误率、精确率、召回率和F1-score等。 在分类任务中，基础指标是混淆矩阵，在混淆矩阵的基础上可以产生精确率、召回率等不同的评价指标。
混淆矩阵 当把数据集中的正负样本分开来看时，将会产生以下四个指标： TP(True Positive)：真正例，即该样本的真实标签为正类，预测也为正类 TN(True Negative)：真反例，即该样本的真实标签为负类，预测也为负类 FP(False Positive)：假正例，即该样本的真实标签为负类，但预测为正类 FN(False Negative)：假反例，即该样本的真实标签为正类，但预测为负类 将上述四个指标放在一个矩阵中，即可得到混淆矩阵。
真实情况预测结果正例反例正例TPFN反例FPTN错误率(Error Rate) 即分类错误的样本数占样本总数的比例，公式如下：
$$ ErrorRate=\frac{FN+FP}{TP+FN+FP+TN} $$
准确率(Accuracy) 即分类正确的样本数占样本总数的比例，公式如下：
$$ ACC=\frac{TP+TN}{TP+FN+FP+TN} $$
精确率(Precision) 又称查准率，即被预测为正例的样本中真实标签为正例的比例，公式如下：
$$ P=\frac{TP}{TP+FP} $$</description>
    </item>
    
    <item>
      <title>test</title>
      <link>https://gdy0924.github.io/posts/test/</link>
      <pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>https://gdy0924.github.io/posts/test/</guid>
      <description>原文 壬戌之秋，七月既望，蘇子與客泛舟遊於赤壁之下。清風徐來，水波不興。舉酒屬客，誦明月之詩，歌窈窕之章。少焉，月出於東山之上，徘徊於斗牛之間。白露橫江，水光接天。縱一葦之所如，凌萬頃之茫然。浩浩乎如馮虛御風，而不知其所止；飄飄乎如遺世獨立,羽化而登仙。
於是飲酒樂甚，扣舷而歌之。歌曰：“桂棹兮蘭槳，擊空明兮溯流光。渺渺兮予懷，望美人兮天一方。”客有吹洞簫者，倚歌而和之。其聲嗚嗚然，如怨如慕，如泣如訴；餘音嫋嫋，不絕如縷。舞幽壑之潛蛟，泣孤舟之嫠婦。
蘇子愀然，正襟危坐，而問客曰：“何爲其然也？”客曰：“‘月明星稀，烏鵲南飛。’此非曹孟德之詩乎？西望夏口，東望武昌，山川相繆，鬱乎蒼蒼，此非孟德之困於周郎者乎？方其破荊州，下江陵，順流而東也，舳艫千里，旌旗蔽空，釃酒臨江，橫槊賦詩，固一世之雄也，而今安在哉？況吾與子漁樵於江渚之上，侶魚蝦而友麋鹿，駕一葉之扁舟，舉匏樽以相屬。寄蜉蝣於天地，渺滄海之一粟。哀吾生之須臾，羨長 江之無窮。挾飛仙以遨遊，抱明月而長終。知不可乎驟得，託遺響於悲風。”
蘇子曰：“客亦知夫水與月乎？逝者如斯，而未嘗往也；盈虛者如彼，而卒莫消長也。蓋將自其變者而觀之，則天地曾不能以一瞬；自其不變者而觀之，則物與我皆無盡也，而又何羨乎！且夫天地之間，物各有主，苟非吾之所有，雖一毫而莫取。惟江上之清風，與山間之明月，耳得之而爲聲，目遇之而成色，取之無禁，用之不竭。是造物者之無盡藏也，而吾與子之所共適。”(共適 一作：共食) 客喜而笑，洗盞更酌。餚核既盡，杯盤狼籍。相與枕藉乎舟中，不知東方之既白。</description>
    </item>
    
  </channel>
</rss>
